{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562b7dc0-d031-4a11-8fd2-f60d1a5e6341",
   "metadata": {},
   "source": [
    "# Cleaned notebook of functions and classes used in the corona project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8d59f-48f0-45c4-8dc3-b4f318ee17f1",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475a1f0-3516-4547-9c68-b200e8eafc4d",
   "metadata": {},
   "source": [
    "### GISAID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff198958-d9f5-4a68-b2d7-9dbb2842efd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import clipboard\n",
    "\n",
    "def download_gisaid_files(files: list[str], user: str, password: str) -> None:\n",
    "    '''\n",
    "    Downloads all the sequences in the list given to the function. \n",
    "    '''\n",
    "    \n",
    "    clipped = ' '.join(files)\n",
    "    clipboard.copy(clipped)\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.epicov.org/epi3/frontend#df91e')\n",
    "    time.sleep(4)\n",
    "    \n",
    "    username = driver.find_element(By.NAME, 'login')\n",
    "    username.send_keys(user)\n",
    "    passw = driver.find_element(By.NAME, 'password')\n",
    "    passw.send_keys(password)\n",
    "    login_button = driver.find_element(By.CLASS_NAME, 'form_button_submit')\n",
    "    login_button.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    search = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[2]/div/div[1]/div/div/div[3]')\n",
    "    search.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    select = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[2]/div/div[2]/div[2]/div[2]/div[3]/button[2]')\n",
    "    select.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    driver.switch_to.frame(driver.find_element(By.TAG_NAME,  'iframe'))\n",
    "    time.sleep(4)\n",
    "\n",
    "    text_area = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[1]/div/div[1]/table[2]/tbody/tr/td/div/div[1]/textarea')\n",
    "    text_area.send_keys(Keys.COMMAND, 'v')\n",
    "    time.sleep(3)\n",
    "\n",
    "    ok = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[2]/div/div/div[2]/div/button')\n",
    "    ok.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    actions = ActionChains(driver)\n",
    "    actions.send_keys(Keys.RETURN)\n",
    "    actions.perform()  \n",
    "    time.sleep(4)\n",
    "\n",
    "    driver.switch_to.parent_frame()\n",
    "    time.sleep(4)\n",
    "\n",
    "    download = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[2]/div/div[2]/div[2]/div[2]/div[3]/button[4]')\n",
    "    download.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    driver.switch_to.frame(driver.find_element(By.TAG_NAME,  'iframe'))\n",
    "    time.sleep(4)\n",
    "\n",
    "    input_auger = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[1]/div/div/table[1]/tbody/tr/td[2]/div/div[1]/div[2]/div[1]/input')\n",
    "    input_auger.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    get_files = driver.find_element(By.XPATH, '/html/body/form/div[5]/div/div[2]/div/div/div[2]/div/button')\n",
    "    get_files.click()\n",
    "    time.sleep(230)\n",
    "    driver.quit()\n",
    "    \n",
    "def split_dataframe_chunk(path_to_csv: str, chunk_size: 5000) -> list[pd.DataFrame]:\n",
    "    '''\n",
    "    Splits the csv file into chunks of < the chunk_size.\n",
    "    '''\n",
    "    df = pd.read_csv(path_to_csv, header=None, names=['id'])\n",
    "    chunks = np.ceil(len(df) / chunk_size)\n",
    "    return np.array_split(df, chunks)\n",
    "\n",
    "def save_gisaid_csv(path_to_csv: str, output_folder: str, chunk_size=5000) -> None:\n",
    "    '''\n",
    "    Saves chunks of the input csv file into chunks of desired sizes. \n",
    "    '''\n",
    "    \n",
    "    chunks = split_dataframe_chunk(path_to_csv, chunk_size)\n",
    "    \n",
    "    path = pathlib.Path(output_folder)\n",
    "    path.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for num, file in enumerate(chunks, 1):\n",
    "        name = path / f'{num}.csv'\n",
    "        file.to_csv(name, index=False)\n",
    "        \n",
    "\n",
    "def download_gisaid_files_from_csv(path_csv: str, username: str, password: str) -> list:\n",
    "    '''\n",
    "    Downloads data from GISAID from the csv files given as argument to the function. \n",
    "    '''\n",
    "    path_csv = pathlib.Path(path_csv)\n",
    "    csv_files = [file for file in path_csv.iterdir() if file.suffix == '.csv']\n",
    "    \n",
    "    for file in csv_files:\n",
    "        sequences = pd.read_csv(file).id.to_list()\n",
    "        not_downloaded = []\n",
    "        try:\n",
    "            download_gisaid_files(sequences, username, password)\n",
    "            print(f'{file.name}')\n",
    "        except Exception as e:\n",
    "            print(f'{file.name} was not downloaded to to exception {e}')\n",
    "            not_downloaded.append(file.name)\n",
    "            \n",
    "    return not_downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ade124-49c8-4be8-9974-5a43b797c270",
   "metadata": {},
   "source": [
    "### Outbreak.info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5dc7e-9ae0-4f06-b03c-a1fed628967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "\n",
    "\n",
    "def download_mutations_table(pango: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Downloads the table of characteristic mutations of the given pango lineage. \n",
    "    '''\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.headless = True\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "\n",
    "    driver.get(f'https://outbreak.info/situation-reports?pango={pango}')\n",
    "    time.sleep(60)\n",
    "    number = driver.find_element(By.XPATH, '/html/body/div/div/div/div/div[5]/div/div[1]/div[3]/div/span')\n",
    "    pattern = re.compile(r'(\\d*,*\\d+)')\n",
    "    number_sequences = int(re.findall(pattern, number.text)[0].replace(',', ''))\n",
    "\n",
    "    df = pd.read_html(driver.page_source)[0]\n",
    "    df['pango'] = pango\n",
    "    df['number_sequences'] = number_sequences\n",
    "    df.rename(columns={'amino acid': 'amino_acid'}, inplace=True)\n",
    "    driver.quit()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def save_mutation_table(pango: str, folder: str) -> None:\n",
    "    '''\n",
    "    Saves the mutation table from outbreak.info in a csv file.\n",
    "    '''\n",
    "    try:\n",
    "        df = download_mutations_table(pango)\n",
    "        path = pathlib.Path(folder, f'{pango}.csv')\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f'{pango} saved')\n",
    "    except Exception as e:\n",
    "        print(f'{pango} failed due to {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acb2ca-4c75-48f0-a996-d98defe97196",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83d125-9d3f-4b7f-a1e7-1ae5ee234bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextclade_mutations(csv: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Reads the csv file from nextclade and returns a df of mutations.\n",
    "    '''\n",
    "    df = pd.read_csv(csv, sep='\\t')\n",
    "    df['aaSubstitutions'] = df['aaSubstitutions'].str.split(',')\n",
    "    df = df['aaSubstitutions'].explode(ignore_index=True).to_frame()\n",
    "    df.rename(columns={'aaSubstitutions': 'aa'}, inplace=True)\n",
    "    df[['gene', 'amino_acid']] = df['aa'].str.split(':', expand=True)\n",
    "    df.drop(columns=['aa'], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c36ae-2b9f-4b37-8688-c8ee8c78fd25",
   "metadata": {},
   "source": [
    "## Machine learning classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5346fb-c2cc-44a5-b010-cd606954cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class CoronaData:\n",
    "    '''\n",
    "    Keeps the information and the sequence of the corona lineages in a pandas dataframe. \n",
    "    Methods for manipulation the sequences for creating k-mers and similar.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, path_meta: str, path_fasta: str, multiple: bool = False):\n",
    "        if multiple:\n",
    "            self.df = self.__multiple_corona_dataframe(path_meta, path_fasta)\n",
    "        else:\n",
    "            self.df = self.__corona_dataframe(path_meta, path_fasta)\n",
    "    \n",
    "    def __corona_dataframe(self, path_meta: str, path_fasta: str) -> pd.DataFrame:\n",
    "        '''\n",
    "        Returns a dataframe with the id, pangolin, gisaid clade, author, \n",
    "        length and sequence of all corona files.\n",
    "        '''\n",
    "        df = pd.read_csv(path_meta, sep='\\t', parse_dates=['date'])\n",
    "        df = df[['strain', 'pangolin_lineage', 'GISAID_clade', 'originating_lab', 'date']]\n",
    "        df['strain'] = [x.split('/')[2] for x in df['strain']]\n",
    "        \n",
    "        sequences = list(SeqIO.parse(path_fasta, 'fasta'))\n",
    "        df['sequence'] = [str(x.seq) for x in sequences]\n",
    "        \n",
    "        new_names = ['id', 'pangolin', 'clade', 'originating_lab', 'date', 'sequence']\n",
    "        df.columns = new_names\n",
    "\n",
    "        df['raw_length'] = [len(x) for x in df['sequence']]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def __multiple_corona_dataframe(self, path_meta: str, path_fasta: str) -> pd.DataFrame:\n",
    "        '''\n",
    "        If folder contains multiple fasta and tsv files, everything is concatenated into \n",
    "        one big dataframe.\n",
    "        '''\n",
    "        path_meta = pathlib.Path(path_meta)\n",
    "        path_fasta = pathlib.Path(path_fasta)\n",
    "        \n",
    "        metas = sorted([meta for meta in path_meta.iterdir() if meta.suffix == '.tsv'])\n",
    "        fastas = sorted([fasta for fasta in path_fasta.iterdir() if fasta.suffix == '.fasta'])\n",
    "        \n",
    "        dataframes = [self.__corona_dataframe(meta, fasta) for meta, fasta in zip(metas, fastas)]\n",
    "        df = pd.concat(dataframes) \n",
    "        \n",
    "        return df \n",
    "    \n",
    "    def trim_sequence(self) -> None:\n",
    "        '''\n",
    "        Operates on the self.df object.\n",
    "        Removes everything from the sequence which is not ATCG.\n",
    "        Creates a new column with the length of the trimmed sequence.\n",
    "        '''\n",
    "        self.df['sequence'] = [re.sub(r'[^ATCG]', '', x) for x in self.df['sequence']]\n",
    "        self.df['trimmed_length'] = [len(x) for x in self.df['sequence']]\n",
    "        \n",
    "    def kmerize(self, k: int = 6) -> None:\n",
    "        '''\n",
    "        Operates on the self.df object.\n",
    "        Kmerizes the sequences into length of k and return a string of the kmers. \n",
    "        Contains the inner function 'get_kmer'.\n",
    "        '''\n",
    "        def get_kmer(sequence, k):\n",
    "            return [sequence[x: x + k] for x in range(len(sequence) - k + 1)]\n",
    "                \n",
    "        self.df['sequence'] = [' '.join(get_kmer(x, k)) for x in self.df['sequence']]\n",
    "\n",
    "    def train_test_split(self, train_size: float = 0.8) -> None:\n",
    "        '''\n",
    "        Splits the self.df object into a train and test df based on the split value.\n",
    "        '''\n",
    "        self.train, self.test = train_test_split(self.df, random_state=42, stratify=self.df.pangolin, train_size=train_size)\n",
    "        \n",
    "    def vectorize(self, vectorizer: CountVectorizer) -> None:\n",
    "        '''\n",
    "        Vectorizes the sequence of the dataframe and returns a transformed scarce matrix.\n",
    "        '''        \n",
    "        self.transformed = vectorizer.transform(self.df.sequence)\n",
    "        \n",
    "    def classify(self, classifier: MultinomialNB) -> None:\n",
    "        '''\n",
    "        Classifies the transformed data and returns predictions about\n",
    "        the sequences. \n",
    "        '''\n",
    "        self.predicted = classifier.predict(self.transformed)\n",
    "        \n",
    "    def split_sequence(self, k: int = 6) -> None:\n",
    "        '''\n",
    "        Splits sequence into chunks with len. E.g 'abcde' -> 'ab cd e'.\n",
    "        '''\n",
    "        def make_chunks(sequence, k):\n",
    "            chunks = []\n",
    "            for i in range(0, len(sequence), 3):\n",
    "                sek\n",
    "                new_list.append(sekvens)\n",
    "            return chunks\n",
    "        \n",
    "        self.df['sequence'] = [' '.join(make_chunks(x, k)) for x in self.df['sequence']]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9ab22-4eca-40a5-9806-7b08369c4437",
   "metadata": {},
   "source": [
    "# Tankar och ideer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d1498-923a-4b16-9470-7bd2f94246ab",
   "metadata": {},
   "source": [
    "### How to search mutations with query on outbreak.info\n",
    "\n",
    "&muts={gene}%3{substitution}\n",
    "\n",
    "### Also possible to filter the mutation df with the mutations of choice\n",
    "\n",
    "Everything now is just with substitutions and without deletion. Maybe add deletion later?\n",
    "\n",
    "# Idea\n",
    "\n",
    "To test how many similar substitutions the query has to all the designated lineages in the database, use the set union of the query and the mutations characteristic to find the ratio. \n",
    "\n",
    "Also possible to compare the query to all the mutations of all sequences in sweden to find the sequence that is most similar! \n",
    "\n",
    "# NLP on the mutation table of all sequence from Sweden!\n",
    "Do TF-IDF on the mutatitons e.g. S:K128L and calculate the tf-idf for all the lineages! This will probably result in just a few common mutations which can be used for identifying the real characteriztics!!\n",
    "\n",
    "Se om en mutation är ny för en sekvens genom att jämföra alla mutationer i en sekvens med ett union set av alla mutationer tillgängliga i databasen. Om en mutation inte finns i den nya sekvensen kan detta kanske vara en ny variant eller nåt att hålla ögonen på? \n",
    "\n",
    "## nextclade command\n",
    "nextclade \\\n",
    "   --in-order \\\n",
    "   --input-fasta 1648629336772.sequences.fasta \\\n",
    "   --input-dataset data/sars-cov-2 \\\n",
    "   --output-tsv output/nextclade.tsv \\\n",
    "   --output-tree output/nextclade.auspice.json \\\n",
    "   --output-dir output/ \\\n",
    "   --output-basename nextclade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
